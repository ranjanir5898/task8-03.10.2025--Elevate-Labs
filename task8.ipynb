{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ba1c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "# Load dataset (adjust encoding if needed) \n",
    "file_path = \"Sample - Superstore.csv\" \n",
    "df = pd.read_csv(file_path, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9609d570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before cleaning:\n",
      " Row ID           0\n",
      "Order ID         0\n",
      "Order Date       0\n",
      "Ship Date        0\n",
      "Ship Mode        0\n",
      "Customer ID      0\n",
      "Customer Name    0\n",
      "Segment          0\n",
      "Country          0\n",
      "City             0\n",
      "State            0\n",
      "Postal Code      0\n",
      "Region           0\n",
      "Product ID       0\n",
      "Category         0\n",
      "Sub-Category     0\n",
      "Product Name     0\n",
      "Sales            0\n",
      "Quantity         0\n",
      "Discount         0\n",
      "Profit           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Check for missing values\n",
    "print(\"Missing values before cleaning:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dfc6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill or drop missing values (depending on column) \n",
    "df['Postal Code'] = df['Postal Code'].fillna(0) # Replace missing Postal Code with 0 \n",
    "df = df.dropna(subset=['Order ID', 'Customer ID']) # Drop rows with missing critical IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f7349e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Remove duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d15dcd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Convert dates to datetime\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'], errors='coerce') \n",
    "df['Ship Date'] = pd.to_datetime(df['Ship Date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e898a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Standardize text columns\n",
    "text_cols = df.select_dtypes(include='object').columns\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].str.strip() # Remove leading/trailing spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93fdf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Drop unnecessary columns (optional)\n",
    "# 'Row ID' is just an index, so we can drop it df = df.drop(columns=['Row ID'])\n",
    "df = df.drop(columns=['Row ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48c1c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Reset index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "032ea5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9994 entries, 0 to 9993\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   Order ID       9994 non-null   object        \n",
      " 1   Order Date     9994 non-null   datetime64[ns]\n",
      " 2   Ship Date      9994 non-null   datetime64[ns]\n",
      " 3   Ship Mode      9994 non-null   object        \n",
      " 4   Customer ID    9994 non-null   object        \n",
      " 5   Customer Name  9994 non-null   object        \n",
      " 6   Segment        9994 non-null   object        \n",
      " 7   Country        9994 non-null   object        \n",
      " 8   City           9994 non-null   object        \n",
      " 9   State          9994 non-null   object        \n",
      " 10  Postal Code    9994 non-null   int64         \n",
      " 11  Region         9994 non-null   object        \n",
      " 12  Product ID     9994 non-null   object        \n",
      " 13  Category       9994 non-null   object        \n",
      " 14  Sub-Category   9994 non-null   object        \n",
      " 15  Product Name   9994 non-null   object        \n",
      " 16  Sales          9994 non-null   float64       \n",
      " 17  Quantity       9994 non-null   int64         \n",
      " 18  Discount       9994 non-null   float64       \n",
      " 19  Profit         9994 non-null   float64       \n",
      "dtypes: datetime64[ns](2), float64(3), int64(2), object(13)\n",
      "memory usage: 1.5+ MB\n",
      "None\n",
      "Shape: (9994, 20)\n",
      "Missing values after cleaning:\n",
      " Order ID         0\n",
      "Order Date       0\n",
      "Ship Date        0\n",
      "Ship Mode        0\n",
      "Customer ID      0\n",
      "Customer Name    0\n",
      "Segment          0\n",
      "Country          0\n",
      "City             0\n",
      "State            0\n",
      "Postal Code      0\n",
      "Region           0\n",
      "Product ID       0\n",
      "Category         0\n",
      "Sub-Category     0\n",
      "Product Name     0\n",
      "Sales            0\n",
      "Quantity         0\n",
      "Discount         0\n",
      "Profit           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Final check # -------------------------------\n",
    "print(\"Cleaned dataset info:\")\n",
    "print(df.info())\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Missing values after cleaning:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb84cac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved as Superstore_Cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataset\n",
    "df.to_csv(\"Superstore_Cleaned.csv\", index=False)\n",
    "print(\"Cleaned dataset saved as Superstore_Cleaned.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
